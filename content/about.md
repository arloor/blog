---
title: "About Arloor"
date: 2019-08-21T22:03:30+08:00
---

**信条：程序员的职责是Research and Development，而不是死记硬背！！**

## 专业技能

- 常用开发语言：
    - Java 80%
    - go 20%
- 开源贡献：
    - Github获得1854 star，122 follower
    - [Shell编程以设置iptables NAT转发](https://github.com/arloor/iptablesUtils)获得1100Star
    - [全功能Http代理](https://github.com/arloor/HttpProxy)及其[客户端](https://github.com/arloor/forward)
- 源码阅读：
    - [Redis](https://www.arloor.com/tags/redis/)
    - [Elasticsearch](https://www.arloor.com/tags/elasticsearch/)
    - [Netty](https://www.arloor.com/tags/netty/)
    - [Skywalking监控系统](https://www.arloor.com/tags/%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/)
- 大型项目：
    - 美团唯一链路追踪系统的开发，广泛使用Redis、ElasticSearch、Hbase、Kafka、RPC等技术。
    - 美团唯一监控系统开发，熟悉指标采集、上报、分析、聚合、存储、降采样的实现。
    - 使用go语言开发Redis集群代理，让用户像使用单机Redis一样使用Redis集群，在此过程中熟悉Redis resp协议、拷贝、分片、故障迁移。
    - 基于ElasticSearch的搜索平台建设。

## 工作经历

1. 2019年6月30日，于南京大学软件学院本科毕业，获工科学士学位。
2. 2019年7月8日——2020年6月12日，供职于招商银行信用卡中心，在IT部门平台架构组工作。
3. 2020年6月15日，入职美团，在基础技术部/基础架构部/系统软件中心/监控系统组工作。

### 大盘迁移推进

在天网迁移至Raptor大盘的推进过程中有多方面的难点：1. Raptor各指标模型差异大，存储实现也各异，接入大盘指标复杂；2. 面对全公司所有的业务部门，沟通成本高；3. Raptor大盘基础薄弱，性能和稳定性较差；4. 原天网大盘经过了多年的打磨，功能点多，用户覆盖面广，用户需求各异。

时间紧，任务重，为了保证项目的如期落地，我秉持客户为先的价值观，使用技术与运营并行的方法论。在用户层面，积极与用户沟通，对于用户需求做到当周开发，次周上线，做到凡事有交代，件件有着落。在技术层面，我首先补齐大盘原有的工程化不足，解决大量代码和设计问题，提升大盘的性能和稳定性，核心接口平均耗时降低至1s以下，大多数大盘实现秒开；而后在对大盘和Raptor指标模型有充分了解的基础上，划分大盘API和各指标领域查询的边界，建立统一的领域查询模型，抽象出转译层、查询层、渲染层，最终降低了Raptor各指标模型接入大盘的成本和大盘维护的成本。

Raptor大盘最终成为统一多端监控数据的可视化平台，集成数据展示和实时告警能力，为用户提供一站式的监控解决方案。也赢得了不少业务和SRE同学的认同：“大盘很重要，我们每天巡检都会看”，“我们计划将所有核心指标的告警都基于大盘来做”，“我们想把所有天网告警都迁移到Raptor上”。

### Mtrace迭代演进

Mtrace刚交接到我们团队时，因为长期缺乏维护和迭代，存在若干的性能和稳定性问题，比如：持久化延时高，数据丢失，域名5xx告警和拉跪squirrel集群等等。同时Mtrace的能力也和开源社区、业界竞品产生了不少差距，具体体现在缺少性能指标、拓扑功能弱、只支持跨进程埋点。

团队刚刚接收Mtrace项目时，我从零学习分布式链路追踪的思想、设计和实现，认识到Trace作为可观测性三大支柱（也称主要信号）之一的重要地位。再落到实际工作中，脚踏实地从4个方面优化mtrace的性能和稳定性：1. 分析层吞吐量提升；2. 拓扑查询性能优化；3. 大拓扑关系治理；4. FullGC问题治理。具体实践过程中，一方面从具体问题出发，分析问题根因，逐个解决具体问题；另一方面通过架构调整，提升分析层性能，解决数据丢失问题。最终分析层平均耗时从8ms降低至0.8ms，吞吐量从700万/min提升至2400万/min。通过大拓扑治理，大大提升redis集群稳定性，redis集群故障不再发生。拓扑查询接口tp99降低25倍（1000ms降低至40ms）, tp999降低50倍（20000ms降低至400ms）。

在解决以上技术债务的基础上，我开始Mtrace的迭代演进之路。首先推动Mtrace2.0的架构落地，主要有如下三点：1. 建设Mtrace收集组件，形成独立的数据上报通道；2. 将实时分析场景与近实时场景进行拆分，保证实时场景的性能和稳定性。3. 建立中心化的配置服务，Mtrace平台可下发配置，从而实现更多定制能力，丰富Mtrace的产品功能。

新架构让Mtrace提供更多功能变得可行。我充分调研了业内产品的功能，包括阿里ARMS链路追踪、阿里云SLS、腾讯云性能监控、skywalking、jaeger等，其次向内看，调研了业务部门的稳定性保障团队、测试团队对trace功能的需求。在此基础上Mtrace提供了以场景为中心的、包含性能指标的、支持小时级别的拓扑分析功能，为业务同学提供更好的全链路监控体验。以交易系统平台提出内部埋点需求为契机，充分调研业界trace系统的实现细节，利用Mtrace2.0新架构，我落地了Mtrace服务内埋点的能力，完善了技术体系，缩小了与开源标准、业界竞品的差距。

### 为业务同学提供解决方案

监控遇到的客服问题，不只是Raptor的问题，往往横向扩展到其他中间件例如Octo、Mafka等，纵向深入到Hulk容器状态层面等。为业务提供solution而不是support是基础技术部的理念。我的理解是support是不越边界、点到即止，solution是以解决问题为目标、不绝不休。solution需要我们做更多，需要基础技术部内更好地协同。秉持该理念，对于边界不清晰或需要多团队协同处理的问题，我积极与兄弟团队沟通，尽力做统一的接口人，尽力让用户只需要“跑一遍”。

用户反馈容器仍可ping通但容器内进程（ssh、falcon-agent、业务应用）等都没有了的情况下raptor无任何告警，核心诉求是能向用户推送告警。这可以算监控领域问题，也可以算容器基础设施的问题。本着说清问题、解决问题、为业务提供价值的初衷，我积极与hulk团队沟通，帮助定位到根因是宿主机的磁盘故障，导致宿主机磁盘只读，引发容器故障，推动hulk团队最终给出解决方案：专用集群宿主机磁盘只读自动下线宿主机。

“为什么耗时这么久”是Raptor经常受到的客服问题。看出性能问题这个what比较容易，看出why则比较困难，根据监控指标寻找why是业务RD解决性能问题的重要手段。遇到此类客服问题，我会把最佳实践演示给业务同学看，从logview、Mtrace、系统指标、日志中心中寻找端倪。不光解决了用户的问题，也加强了业务同学排查问题的能力，让用户在一个TT中得到更多的东西，也加强了Raptor的产品口碑和用户信任。

### 团队精神和传帮带

Raptor系统和链路团队组建之初，团队内有较多新同学。为帮助新同学尽快地融入团队，尽快承担起责任，我积极地与团队分享自己的经验。首先我从宏观层面介绍Raptor的产品全景图，系统和链路团队的定位和职责。其次，通过过往整理的9篇文档向新同学介绍团队的Hosts机器指标监控、Mtrace系统、告警的架构和实现，降低新同学的上手成本。最后，在项目的实际交接过程中，按照先易后难的顺序逐步让同学对项目加深理解。遇到提问毫不藏私，从历史到现状，从现状到未来演进，从表现到根因，力求解释清楚，希望从一个简单的问题能帮助新人拓展出更多的认知。不仅让新同学知道what，更知道why，激发新同学更多的思考。对新人既有要求，也有包容，充分尊重，足够信任。一方面我帮助了他们融入，另一方面他们也建立了对我的信任和认可，有利于后面的合作开展。

## 个人简历

[点此查看PDF](/liuganghuan-resume.pdf)

![](/img/青蛙海.png)